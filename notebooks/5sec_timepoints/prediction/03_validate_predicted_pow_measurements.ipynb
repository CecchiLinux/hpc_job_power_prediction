{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import pandas as pd\n",
    "import errno    \n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "#pd.set_option('display.max_rows', 4000)\n",
    "#pd.set_option('display.max_columns', 500)\n",
    "#pd.set_option('display.width', 1000)\n",
    "\n",
    "'''\n",
    "Author: Enrico Ceccolini\n",
    "    TODO write the description\n",
    "'''\n",
    "\n",
    "datadir = \"/datasets/eurora_data/db1/\"\n",
    "infile_jobs_to_nodes = datadir + \"job_nodes.csv\"\n",
    "infile_nodes = datadir + \"nodes.csv\"\n",
    "\n",
    "suffix = \"_5sec_\"\n",
    "### select an interval from\n",
    "## 1 settings wholeData\n",
    "#interval_comment_whole = \"WholeData\"\n",
    "\n",
    "### select an interval from\n",
    "## 2 settings Andrea\n",
    "interval_comment = \"Andrea\"\n",
    "start_time = pd.to_datetime('2014-03-31')\n",
    "end_time = pd.to_datetime('2014-05-01')\n",
    "#infile_jobs = datadir + \"april_long_jobs.csv\"\n",
    "\n",
    "## 3 settings Alina\n",
    "interval_comment = \"Alina\"\n",
    "#start_time = pd.to_datetime('2014-06-30')\n",
    "tart_time = pd.to_datetime('2014-03-31')\n",
    "end_time = pd.to_datetime('2014-11-01')\n",
    "train_start_time = pd.to_datetime('2014-06-30')\n",
    "train_end_time = pd.to_datetime('2014-10-01')\n",
    "test_end_time = pd.to_datetime('2014-11-01')\n",
    "\n",
    "\n",
    "infile_long_jobs = datadir + \"CPUs/\" + interval_comment + \"/\" + interval_comment + \"_long_jobs_real_pow\"\n",
    "\n",
    "## notice that 43 doesn't exists in the db\n",
    "#nodes=['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64']\n",
    "#nodes=['01'] # test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jobs_to_nodes_whole_data contains 469095 records\n",
      "There are 336787 long jobs in the Alina's interval\n"
     ]
    }
   ],
   "source": [
    "jobs_to_nodes_whole_data = pd.read_csv(infile_jobs_to_nodes, index_col=0)\n",
    "print(\"jobs_to_nodes_whole_data contains {} records\".format(jobs_to_nodes_whole_data.shape[0]))\n",
    "\n",
    "jobs = pd.read_csv(infile_long_jobs + \".csv\", index_col=0)\n",
    "print(\"There are {} long jobs in the {}'s interval\".format(jobs.shape[0], interval_comment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set contains 24918 records\n"
     ]
    }
   ],
   "source": [
    "jobs_not_zero_quality = jobs[jobs['real_pow'] > 0]\n",
    "\n",
    "jobs_test = jobs_not_zero_quality[pd.to_datetime(jobs_not_zero_quality['end_time']) <= test_end_time]\n",
    "jobs_test = jobs_test[pd.to_datetime(jobs_test['run_start_time']) > train_end_time]\n",
    "print(\"test set contains {} records\".format(jobs_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after the clean, jobs_to_nodes_whole_data contains 444610 records\n"
     ]
    }
   ],
   "source": [
    "### clean the data\n",
    "# remove jobs runned on the inexistent node 129\n",
    "jobs_to_nodes_whole_data = jobs_to_nodes_whole_data[jobs_to_nodes_whole_data['node_id'] != 129] \n",
    "# remove jobs with the same id that runned on the same node\n",
    "jobs_to_nodes_whole_data = jobs_to_nodes_whole_data.drop_duplicates(subset=['job_id_string', 'node_id'])\n",
    "print(\"after the clean, jobs_to_nodes_whole_data contains {} records\".format(jobs_to_nodes_whole_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_jobs_to_nodes contains 25569 records\n"
     ]
    }
   ],
   "source": [
    "### merge the info from the two tables\n",
    "merged_jobs_to_nodes = pd.merge(jobs_test, jobs_to_nodes_whole_data, how='left', on='job_id_string')\n",
    "print(\"merged_jobs_to_nodes contains {} records\".format(merged_jobs_to_nodes.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.read_csv(infile_nodes, index_col=0)\n",
    "#print(nodes.shape[0])\n",
    "#nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the file where to calculate the approximated consumption\n",
    "#### part 1\n",
    "#infile_node = datadir + \"CPUs/\" + interval_comment + \"/node01\" + suffix + interval_comment + \"_active_cores_and_jobs\"\n",
    "#node_data = pd.read_csv(infile_node + \".csv\")\n",
    "\n",
    "#all_time_interval_power_consumption = pd.DataFrame(node_data['timestamp'])\n",
    "#infile_validate_approx = datadir + \"CPUs/\" + interval_comment + \"/validate_approx_perUserJob\" + interval_comment + \".csv\"\n",
    "#all_time_interval_power_consumption.to_csv(infile_validate_approx)\n",
    "\n",
    "\n",
    "### part 2\n",
    "#all_time_interval_power_consumption = pd.read_csv(infile_validate_approx, index_col=0)\n",
    "#all_time_interval_power_consumption.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "period = (test_end_time - train_end_time)\n",
    "period = period.total_seconds() / 5 # total seconds / 5\n",
    "\n",
    "interval_serie = pd.date_range(train_end_time, periods=period, freq='5s')\n",
    "frame = { 'timestamp': interval_serie }\n",
    "\n",
    "all_time_interval_power_consumption = pd.DataFrame(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-10-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-10-01 00:00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-10-01 00:00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-10-01 00:00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-10-01 00:00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014-10-01 00:00:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014-10-01 00:00:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014-10-01 00:00:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014-10-01 00:00:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014-10-01 00:00:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2014-10-01 00:00:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014-10-01 00:00:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2014-10-01 00:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2014-10-01 00:01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2014-10-01 00:01:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2014-10-01 00:01:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2014-10-01 00:01:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2014-10-01 00:01:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2014-10-01 00:01:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2014-10-01 00:01:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2014-10-01 00:01:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2014-10-01 00:01:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2014-10-01 00:01:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2014-10-01 00:01:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2014-10-01 00:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2014-10-01 00:02:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2014-10-01 00:02:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2014-10-01 00:02:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2014-10-01 00:02:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2014-10-01 00:02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535650</th>\n",
       "      <td>2014-10-31 23:57:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535651</th>\n",
       "      <td>2014-10-31 23:57:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535652</th>\n",
       "      <td>2014-10-31 23:57:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535653</th>\n",
       "      <td>2014-10-31 23:57:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535654</th>\n",
       "      <td>2014-10-31 23:57:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535655</th>\n",
       "      <td>2014-10-31 23:57:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535656</th>\n",
       "      <td>2014-10-31 23:58:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535657</th>\n",
       "      <td>2014-10-31 23:58:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535658</th>\n",
       "      <td>2014-10-31 23:58:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535659</th>\n",
       "      <td>2014-10-31 23:58:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535660</th>\n",
       "      <td>2014-10-31 23:58:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535661</th>\n",
       "      <td>2014-10-31 23:58:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535662</th>\n",
       "      <td>2014-10-31 23:58:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535663</th>\n",
       "      <td>2014-10-31 23:58:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535664</th>\n",
       "      <td>2014-10-31 23:58:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535665</th>\n",
       "      <td>2014-10-31 23:58:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535666</th>\n",
       "      <td>2014-10-31 23:58:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535667</th>\n",
       "      <td>2014-10-31 23:58:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535668</th>\n",
       "      <td>2014-10-31 23:59:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535669</th>\n",
       "      <td>2014-10-31 23:59:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535670</th>\n",
       "      <td>2014-10-31 23:59:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535671</th>\n",
       "      <td>2014-10-31 23:59:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535672</th>\n",
       "      <td>2014-10-31 23:59:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535673</th>\n",
       "      <td>2014-10-31 23:59:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535674</th>\n",
       "      <td>2014-10-31 23:59:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535675</th>\n",
       "      <td>2014-10-31 23:59:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535676</th>\n",
       "      <td>2014-10-31 23:59:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535677</th>\n",
       "      <td>2014-10-31 23:59:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535678</th>\n",
       "      <td>2014-10-31 23:59:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535679</th>\n",
       "      <td>2014-10-31 23:59:55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>535680 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 timestamp\n",
       "0      2014-10-01 00:00:00\n",
       "1      2014-10-01 00:00:05\n",
       "2      2014-10-01 00:00:10\n",
       "3      2014-10-01 00:00:15\n",
       "4      2014-10-01 00:00:20\n",
       "5      2014-10-01 00:00:25\n",
       "6      2014-10-01 00:00:30\n",
       "7      2014-10-01 00:00:35\n",
       "8      2014-10-01 00:00:40\n",
       "9      2014-10-01 00:00:45\n",
       "10     2014-10-01 00:00:50\n",
       "11     2014-10-01 00:00:55\n",
       "12     2014-10-01 00:01:00\n",
       "13     2014-10-01 00:01:05\n",
       "14     2014-10-01 00:01:10\n",
       "15     2014-10-01 00:01:15\n",
       "16     2014-10-01 00:01:20\n",
       "17     2014-10-01 00:01:25\n",
       "18     2014-10-01 00:01:30\n",
       "19     2014-10-01 00:01:35\n",
       "20     2014-10-01 00:01:40\n",
       "21     2014-10-01 00:01:45\n",
       "22     2014-10-01 00:01:50\n",
       "23     2014-10-01 00:01:55\n",
       "24     2014-10-01 00:02:00\n",
       "25     2014-10-01 00:02:05\n",
       "26     2014-10-01 00:02:10\n",
       "27     2014-10-01 00:02:15\n",
       "28     2014-10-01 00:02:20\n",
       "29     2014-10-01 00:02:25\n",
       "...                    ...\n",
       "535650 2014-10-31 23:57:30\n",
       "535651 2014-10-31 23:57:35\n",
       "535652 2014-10-31 23:57:40\n",
       "535653 2014-10-31 23:57:45\n",
       "535654 2014-10-31 23:57:50\n",
       "535655 2014-10-31 23:57:55\n",
       "535656 2014-10-31 23:58:00\n",
       "535657 2014-10-31 23:58:05\n",
       "535658 2014-10-31 23:58:10\n",
       "535659 2014-10-31 23:58:15\n",
       "535660 2014-10-31 23:58:20\n",
       "535661 2014-10-31 23:58:25\n",
       "535662 2014-10-31 23:58:30\n",
       "535663 2014-10-31 23:58:35\n",
       "535664 2014-10-31 23:58:40\n",
       "535665 2014-10-31 23:58:45\n",
       "535666 2014-10-31 23:58:50\n",
       "535667 2014-10-31 23:58:55\n",
       "535668 2014-10-31 23:59:00\n",
       "535669 2014-10-31 23:59:05\n",
       "535670 2014-10-31 23:59:10\n",
       "535671 2014-10-31 23:59:15\n",
       "535672 2014-10-31 23:59:20\n",
       "535673 2014-10-31 23:59:25\n",
       "535674 2014-10-31 23:59:30\n",
       "535675 2014-10-31 23:59:35\n",
       "535676 2014-10-31 23:59:40\n",
       "535677 2014-10-31 23:59:45\n",
       "535678 2014-10-31 23:59:50\n",
       "535679 2014-10-31 23:59:55\n",
       "\n",
       "[535680 rows x 1 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_time_interval_power_consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_power_consumption(node_str, node_core_idle, interval_size, node_start_time):\n",
    "    \n",
    "    # num_minutes = 535680 \n",
    "    # node_start_time = pd.to_datetime('2014-03-31 00:00:00')\n",
    "    total_approx_power_consumption = pd.Series(0, index=np.arange(interval_size))\n",
    "    total_active_cores = pd.Series(0, index=np.arange(interval_size))\n",
    "    total_real_power_consumption = pd.Series(0, index=np.arange(interval_size))\n",
    "    \n",
    "    jobs_to_node = merged_jobs_to_nodes[merged_jobs_to_nodes['node_id'] == int(node_str)]\n",
    "    #infile_node = datadir + \"CPUs/\" + interval_comment + \"/node\" + node_str + suffix + interval_comment + \"_active_cores_and_jobs\"\n",
    "    #node_data = pd.read_csv(infile_node + \".csv\")\n",
    "    \n",
    "    power_consumption_real = pd.Series(0, index=np.arange(interval_size))\n",
    "    power_consumption_pred = pd.Series(0, index=np.arange(interval_size))\n",
    "    active_cores = pd.Series(0, index=np.arange(interval_size))\n",
    "    \n",
    "    i = 0\n",
    "    num_jobs = jobs_to_node.shape[0]\n",
    "    print(\"{}\".format(num_jobs))\n",
    "    for job_index, job_row in jobs_to_node.iterrows():\n",
    "        \n",
    "        #print(\"{}/{}\".format(i, num_jobs))\n",
    "        i = i + 1\n",
    "        job_start_time = pd.to_datetime(job_row['run_start_time'])\n",
    "        job_end_time = pd.to_datetime(job_row['end_time'])\n",
    "        job_cores = job_row['ncpus']\n",
    "        job_cores_total = job_row['cpu_req']\n",
    "        #job_gpus = row['ngpus']\n",
    "        #job_mics = row['nmics']\n",
    "        job_power_consumption_pred = job_row['predict_online_whole'] * (job_cores / job_cores_total) # real_pow contains the total, here we need only the node portion\n",
    "        job_power_consumption = job_row['real_pow'] * (job_cores / job_cores_total) # real_pow contains the total, here we need only the node portion\n",
    "        \n",
    "        \n",
    "        # print(job_power_consumption_pred)\n",
    "\n",
    "        before_minutes = int((job_start_time - pd.to_datetime(node_start_time) - np.timedelta64(5, 's')) / np.timedelta64(5, 's'))\n",
    "        running_minutes = int((job_end_time - job_start_time) / np.timedelta64(5, 's'))\n",
    "        after_minutes = interval_size - running_minutes - before_minutes\n",
    "\n",
    "        #pred\n",
    "        before_serie = pd.Series(0, index=np.arange(before_minutes))\n",
    "        running_serie = pd.Series(job_power_consumption_pred, index=np.arange(running_minutes))\n",
    "        after_serie = pd.Series(0, index=np.arange(after_minutes))\n",
    "        concat_series = pd.concat([before_serie, running_serie, after_serie], ignore_index=True)\n",
    "        power_consumption_pred = power_consumption_pred.add(concat_series, fill_value=0)\n",
    "        \n",
    "        # real\n",
    "        running_serie = pd.Series(job_power_consumption_real, index=np.arange(running_minutes))\n",
    "        concat_series = pd.concat([before_serie, running_serie, after_serie], ignore_index=True)\n",
    "        power_consumption_real = power_consumption_real.add(concat_series, fill_value=0)\n",
    "\n",
    "        running_serie = pd.Series(job_cores, index=np.arange(running_minutes))\n",
    "        concat_series = pd.concat([before_serie, running_serie, after_serie], ignore_index=True)\n",
    "        active_cores = active_cores.add(concat_series, fill_value=0)\n",
    "\n",
    "        \n",
    "    for x in range(0, 17):\n",
    "        # active_cores[active_cores == x] += (node_core_idle * 16) * (16 - x) / 16\n",
    "        active_cores[active_cores == x] += node_core_idle * (16 - x)\n",
    "    \n",
    "    power_consumption_pred = power_consumption_pred.add(active_cores, fill_value=0)\n",
    "    power_consumption_real = power_consumption_real.add(active_cores, fill_value=0)\n",
    "        \n",
    "    #indices = node_data['active_cores'] == 0\n",
    "    #node_data.at[indices, 'pow_tot'] = node_core_idle * 16\n",
    "    #total_real_power_consumption = node_data['pow_tot']\n",
    "    \n",
    "    return power_consumption_real, power_consumption_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01\n",
      "443\n",
      "02\n",
      "191\n",
      "03\n",
      "409\n",
      "04\n",
      "384\n",
      "05\n",
      "358\n",
      "06\n",
      "334\n",
      "07\n",
      "335\n",
      "08\n",
      "356\n",
      "09\n",
      "266\n",
      "10\n",
      "308\n",
      "11\n",
      "294\n",
      "12\n",
      "308\n",
      "13\n",
      "295\n",
      "14\n",
      "280\n",
      "15\n",
      "286\n",
      "16\n",
      "288\n",
      "17\n",
      "468\n",
      "18\n",
      "178\n",
      "19\n",
      "273\n",
      "20\n",
      "283\n",
      "21\n",
      "270\n",
      "22\n",
      "3\n",
      "23\n",
      "290\n",
      "24\n",
      "237\n",
      "25\n",
      "264\n",
      "26\n",
      "191\n",
      "27\n",
      "270\n",
      "28\n",
      "233\n",
      "29\n",
      "246\n",
      "30\n",
      "215\n",
      "31\n",
      "202\n",
      "32\n",
      "218\n",
      "33\n",
      "2358\n",
      "34\n",
      "1649\n",
      "35\n",
      "1030\n",
      "36\n",
      "1295\n",
      "37\n",
      "1081\n",
      "38\n",
      "942\n",
      "39\n",
      "101\n",
      "40\n",
      "1116\n",
      "41\n",
      "3\n",
      "42\n",
      "845\n",
      "43\n",
      "44\n",
      "1909\n",
      "45\n",
      "1551\n",
      "46\n",
      "795\n",
      "47\n",
      "731\n",
      "48\n",
      "694\n",
      "49\n",
      "1490\n",
      "50\n",
      "973\n",
      "51\n",
      "905\n",
      "52\n",
      "598\n",
      "53\n",
      "13\n",
      "54\n",
      "689\n",
      "55\n",
      "1802\n",
      "56\n",
      "677\n",
      "57\n",
      "828\n",
      "58\n",
      "916\n",
      "59\n",
      "2828\n",
      "60\n",
      "1007\n",
      "61\n",
      "856\n",
      "62\n",
      "727\n",
      "63\n",
      "627\n",
      "64\n",
      "1204\n"
     ]
    }
   ],
   "source": [
    "infile_validate_approx = datadir + \"CPUs/\" + interval_comment + \"/validate_pred_\" + interval_comment + \".csv\"\n",
    "\n",
    "# per ogni nodo sommo quanto è stato il consumo ad ogni intervallo in un vettore parallelo\n",
    "# questo sia per il valore approssimato guardando i job\n",
    "# sia per il valore reale\n",
    "j = 0\n",
    "for node_index, node_row in nodes.iterrows():\n",
    "    node_id = node_row['node_id']\n",
    "    if( int(node_id) < 10):\n",
    "        node_id = \"0\" + str(node_id)\n",
    "    else:\n",
    "        node_id = str(node_id)\n",
    "    print(node_id)\n",
    "    node_core_idle = node_row['core_idle']\n",
    "    \n",
    "    if (node_id != \"43\"):\n",
    "        total_real_power_consumption, total_pred_power_consumption = calculate_power_consumption(node_id, node_core_idle)\n",
    "        all_time_interval_power_consumption[node_id + \"_real\"] = total_real_power_consumption\n",
    "        all_time_interval_power_consumption[node_id + \"_pred\"] = total_approx_power_consumption\n",
    "    \n",
    "\n",
    "    all_time_interval_power_consumption.to_csv(infile_validate_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_time_interval_power_consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_time_interval_power_consumption = all_time_interval_power_consumption[pd.to_datetime(all_time_interval_power_consumption['timestamp']) >= pd.to_datetime('2014-03-31 11:21:00')]\n",
    "all_time_interval_power_consumption = all_time_interval_power_consumption[pd.to_datetime(all_time_interval_power_consumption['timestamp']) <= pd.to_datetime('2014-04-30 20:32:00')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_time_interval_power_consumption = all_time_interval_power_consumption.fillna(55.52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "\n",
    "def plot_line(data_dates, data_real, data_approx, days_interval):\n",
    "    plt.rcParams['figure.figsize'] = (20,5)\n",
    "\n",
    "    X_AXIS_NAME = 'Time (min)'\n",
    "    Y_AXIS_NAME = 'Power (W)'\n",
    "    # TITLE = 'Nodes power consumption - Andrea\\'s data'\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.xaxis.get_majorticklabels()\n",
    "    ax.xaxis.set_major_locator(mdates.DayLocator(interval=days_interval))\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "\n",
    "    dates = []\n",
    "    colors = (\"orange\", \"blue\")\n",
    "    #colors = (\"orange\", \"green\")\n",
    "\n",
    "    for ts in data_dates['timestamp']:\n",
    "        local_d = datetime.strptime(ts, '%Y-%m-%d %H:%M:%S')\n",
    "        dates.append(local_d)\n",
    "\n",
    "\n",
    "    plt.plot(dates, data_real, c=colors[1], alpha=0.5)\n",
    "    plt.plot(dates, data_real, c=colors[1])\n",
    "    \n",
    "    plt.plot(dates, data_approx, c=colors[0], alpha=1)\n",
    "\n",
    "    #plt.plot(dates, data_real, c=colors[1], alpha=0.6, dashes=[2, 2])\n",
    "    \n",
    "    #plt.scatter(dates, node_data['pow_tot_0'] + node_data['pow_tot_1'])\n",
    "\n",
    "    #fig.autofmt_xdate()\n",
    "    plt.xlabel(X_AXIS_NAME, fontsize=20)\n",
    "    plt.ylabel(Y_AXIS_NAME, fontsize=20)\n",
    "    # plt.title(TITLE)\n",
    "\n",
    "    # function to show the plot\n",
    "    plt.show()\n",
    "    #fig.savefig('graph.png', dpi=fig.dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile_approximated = datadir + \"CPUs/\" + interval_comment + \"/validate_approx_\" + interval_comment + \".csv\"\n",
    "approximated_power_consumption = pd.read_csv(infile_approximated)\n",
    "\n",
    "infile_predicted = datadir + \"CPUs/\" + interval_comment + \"/validate_approx_perUserJob\" + interval_comment + \".csv\"\n",
    "predicted_power_consumptions = pd.read_csv(infile_predicted)\n",
    "\n",
    "approximated_power_consumption = approximated_power_consumption[pd.to_datetime(approximated_power_consumption['timestamp']) >= pd.to_datetime('2014-03-31 11:21:00')]\n",
    "approximated_power_consumption = approximated_power_consumption[pd.to_datetime(approximated_power_consumption['timestamp']) <= pd.to_datetime('2014-04-30 20:32:00')]\n",
    "predicted_power_consumptions = predicted_power_consumptions[pd.to_datetime(predicted_power_consumptions['timestamp']) >= pd.to_datetime('2014-03-31 11:21:00')]\n",
    "predicted_power_consumptions = predicted_power_consumptions[pd.to_datetime(predicted_power_consumptions['timestamp']) <= pd.to_datetime('2014-04-30 20:32:00')]\n",
    "\n",
    "approx = approximated_power_consumption.select(lambda col: col.endswith(\"approx\"), axis=1)\n",
    "real = predicted_power_consumptions.select(lambda col: col.endswith(\"real\"), axis=1)\n",
    "predicted = predicted_power_consumptions.select(lambda col: col.endswith(\"pred\"), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx['Total'] = approx.iloc[:, -64:-1].sum(axis=1)\n",
    "real['Total'] = real.iloc[:, -64:-1].sum(axis=1)\n",
    "predicted['Total'] = predicted.iloc[:, -64:-1].sum(axis=1)\n",
    "differences = approx['Total'] - predicted['Total']\n",
    "df = pd.DataFrame(differences)\n",
    "df = df.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n",
    "differences_norm = df['Total']\n",
    "\n",
    "#plot_hist(n_bins=150, data=differences)\n",
    "#plot_hist(n_bins=150, data=differences_norm)\n",
    "\n",
    "#plot_line(data_dates=approximated_power_consumption, data_real=real['Total'], data_approx=predicted['Total'], days_interval=5)\n",
    "plot_line(data_dates=approximated_power_consumption, data_real=approx['Total'], data_approx=predicted['Total'], days_interval=5)\n",
    "\n",
    "#print(\"approximation accuracy: {}\".format(r2_score(real['Total'], approx['Total'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
